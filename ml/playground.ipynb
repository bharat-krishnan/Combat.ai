{"cells":[{"cell_type":"markdown","metadata":{"id":"pd-u8YII3Mm7"},"source":["# Imports\n","\n","we want to import openCV, mediapipe, numpy"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"XWYlOQPR3MnA"},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","import numpy"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"TMF4roTI3MnC"},"outputs":[],"source":["mp_holistic = mp.solutions.holistic # Holistic model\n","mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n","\n","def mediapipe_detection(image, model):\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n","    image.flags.writeable = False                  # Image is no longer writeable\n","    results = model.process(image)                 # Make prediction\n","    image.flags.writeable = True                   # Image is now writeable \n","    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n","    return image, results\n","\n","def draw_landmarks(image, results):\n","    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n","  \n","def draw_styled_landmarks(image, results):\n","\n","    # Draw pose connections\n","    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n","                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n","                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n","                             ) \n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ppyGiyuM3MnD","outputId":"0c233329-e9f6-4548-deb2-ca59f84a5dc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved\n","---------------\n"]}],"source":["cap = cv2.VideoCapture('./videos/Cross.MOV')\n","frameCount = 0\n","jumpFrame = -1\n","pendingSave = False\n","clipStartFrame = 0\n","\n","clipNum = int(input(\"Enter current recording num\"))\n","# Set mediapipe model \n","\n","with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n","    while cap.isOpened():\n","        if jumpFrame >= 0:\n","            jumpFrame -= 1\n","\n","        ret, frame = cap.read()\n","\n","        # Make detections\n","        image, results = mediapipe_detection(frame, holistic)\n","        # print(results)\n","        frame = []\n","        if jumpFrame >= 0:\n","            if results.pose_landmarks:\n","                for res in results.pose_landmarks.landmark:\n","                    frame.append(res.x)\n","                    frame.append(res.y)\n","                    frame.append(res.z)\n","                    frame.append(res.visibility)\n","            else:\n","                for i in range(132):\n","                    frame.append(0)\n","\n","            # frames.append(frame)\n","\n","        # Draw landmarks\n","        draw_styled_landmarks(image, results)\n","\n","        # Show to screen\n","\n","        if pendingSave:\n","            cv2.putText(image, text= str(\"Frames: \" + str(clipStartFrame) + \" - \" + str(frameCount) + \". Press c to save these frames to \" + str(clipNum) + \".npy\"), org=(700, 800),\n","                fontFace= cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0,0,255),\n","                thickness=2, lineType=cv2.LINE_AA)\n","            \n","            cv2.putText(image, text= str(\"Press x to discard these frames\"), org=(700, 850),\n","                fontFace= cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0,0,255),\n","                thickness=2, lineType=cv2.LINE_AA)\n","\n","        cv2.putText(image, text= str(\"Action #\" + str(clipNum) + \". Saving to \" + str(clipNum) + \".npy\"), org=(700, 1000),\n","                fontFace= cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255,0,0),\n","                thickness=2, lineType=cv2.LINE_AA)\n","\n","        cv2.putText(image, text= str(frameCount), org=(500, 300),\n","                fontFace= cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0,0,0),\n","                thickness=2, lineType=cv2.LINE_AA)\n","\n","        cv2.imshow('OpenCV Feed', image)\n","        \n","        wait = 10 if jumpFrame >= 0 else 0\n","        \n","        key = cv2.waitKey(wait)\n","        if key == ord('q'):\n","            break\n","\n","        if pendingSave and key == ord('c'):\n","            pendingSave = False\n","            clipNum += 1\n","            print(\"Saved\")\n","            # print(frames)\n","            print(\"---------------\")\n","            # frames = []\n","            continue\n","        if pendingSave and key == ord('x'):\n","            pendingSave = False\n","            print(\"Discarded\")\n","            print(\"---------------\")\n","            # frames = []\n","            frameCount = clipStartFrame\n","            cap.set(cv2.CAP_PROP_POS_FRAMES, clipStartFrame)\n","            continue\n","        if not pendingSave and jumpFrame < 0:\n","            if key == ord('p'):\n","                frameCount -= 1\n","                cap.set(cv2.CAP_PROP_POS_FRAMES, frameCount)\n","                continue\n","            if key == ord('d'):\n","                frameCount += 100\n","                cap.set(cv2.CAP_PROP_POS_FRAMES, frameCount)\n","                continue\n","            if key == ord('a'):\n","                frameCount -= 100\n","                cap.set(cv2.CAP_PROP_POS_FRAMES, frameCount)\n","                continue\n","            if key == ord('s'):\n","                clipStartFrame = frameCount\n","                jumpFrame = 25\n","                pendingSave = True\n","                continue\n","            else:\n","                frameCount += 1\n","                continue\n","\n","            # Quit when 'q' is pressed\n","\n","        # print(\"pog\")\n","        frameCount += 1\n","\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","\n","# print(frames)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"playground.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.7.1 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"21cc3dc4b5603a15ce10e0f2a275a0772e29eb093bef1b46e9e8aa7d14ea3b3d"}}},"nbformat":4,"nbformat_minor":0}
